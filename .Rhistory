F3<-reshape2::melt(F3.frame)
#F4
f4c1<-c(5,5,5,5,5,5) # number of selections
f4c2<-c(5,5,5,5,5,5) # mean value of selections
f4c3<-c(1,1,1,1,1,1) # SD of selections
F4.frame<-mapply(rnorm, f4c1,f4c2,f4c3) # pick Factor 4 value for each site
F4<-reshape2::melt(F4.frame)
#F5
f5c1<-c(5,5,5,5,5,5) # number of selections
f5c2<-c(50,50,50,50,50,50) # mean value of selections
f5c3<-c(20,20,20,20,20,20) # SD of selections
F5.frame<-mapply(rnorm, f5c1,f5c2,f5c3) # pick Factor 5 value for each site
F5<-reshape2::melt(F5.frame)
Factors<-data.frame(F1$value,F2$value,F3$value,F4$value,F5$value) # combine factors into data table
Sites<-c(paste0("Site", 1:30))
rownames(Factors)<-Sites
colnames(Factors)<-c("F1","F2","F3","F4","F5")
output<-list("model"=NULL, "spplist"=NULL, "raw"=NULL)
output$spplist<-rando.spp
output$model$comm<-make.refcomm(rando.spp, Factors) # output a phyloseq object... will make a list of phyloseq objects
output$model$comm<-filter_taxa(output$model$comm, function(x) sum(x)>0, TRUE)
output$model$EV<-transform_sample_counts(output$model$comm, function(x) x / sum(x) )
output$metrics<-NULL
output$metrics$stats<-NULL
output$metrics$Richness<-NULL
Rich<-estimate_richness(output$model$comm, measures="Observed")
output$metrics$Richness<-Rich
output$metrics$skewness<-median(apply(X = otu_table(output$model$comm), MARGIN=2,FUN = function(x){skewness(x)}))
sample<-set.seqDepth(D,V)
output$raw$comm<-model.rarefy(output$model$comm, sample, D, V)
print("spp selection complete")
sample_data(output$model$comm)$Density<-sample_sums(output$model$comm)# add sample sums
sample_data(output$model$comm)$DensityF<-sample_sums(output$model$comm)/mean(sample_sums(output$model$comm))
sample_data(output$model$comm)$Factor<-as.factor(c(rep("one",5),rep("two",5),rep("three",5),rep("four",5),rep("five",5),rep("six",5)))
sample_data(output$model$comm)$Factor2<-as.factor(c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5),rep(6,5)))
print("start subsampling")
print("subsampling finished")
# remove taxa that have zero abundance in "raw" sequencing run
tax.filt<-filter_taxa(output$raw$comm, function(x)sum(x)>0)
output$metrics$tax.lost<-tax.filt
output$raw$comm<-filter_taxa(output$raw$comm, function(x)sum(x)>0, TRUE)
# remove taxa that are not kept from sequencing so that they don't penalize downstream methods
output$model$comm<-prune_taxa(tax.filt, output$model$comm)
output$model$EV<-prune_taxa(tax.filt, output$model$EV)
# for each species: measure prevalence
prevalence=apply(X = otu_table(output$model$comm), MARGIN=1,FUN = function(x){sum(x > 0)})
# for each species: measure relative abundance (proportion of total counts?
p.abund<-transform_sample_counts(output$model$comm, function(x) x/sum(x) )
mean_abundance<-apply(X = otu_table(p.abund), MARGIN=1,FUN = function(x){mean(x)})
sd_abundance<-apply(X = otu_table(p.abund), MARGIN=1,FUN = function(x){sd(x)})
# create a tax table for whole dataset ...
tab<-data.frame(prevalence, mean_abundance, sd_abundance)
tab$names<-rownames(tab)
output$model$SpeciesMeta<-tab
output$model$R<-lm.test(output$model$comm)
# make expected value
s<-sample_sums(output$raw$comm)
s2<-as.data.frame(as.matrix(otu_table(output$model$EV)))
s2<-for (i in 1:ncol(s2)) {s2[,i]<-s2[,i]*s[i]}
otu_table(output$model$EV)<-otu_table(output$model$EV, taxa_are_rows=TRUE)
M.Eval<-apply(X = otu_table(output$model$EV), MARGIN=1,FUN = function(x){mean(x[x>0])})
#output$model$SpeciesMeta$USI<-output$model$SpeciesMeta$
# create a tax table for whole dataset ...
tab<-data.frame(prevalence, mean_abundance, sd_abundance, M.Eval)
tab$names<-rownames(tab)
output$model$SpeciesMeta<-tab
output$model$R<-lm.test(output$model$comm)
sample_data(output$raw$comm)<-sample_data(output$model$comm)
output$model$PERMANOVA<-make.PERMANOVA(output$model$comm)
output$model$rarecurve<-ggrare(output$model$comm, 50, color="Factor")
print("metadata complete")
# implement each normalization function
for (i in 1:length(method)){
a<-get(method[i])
#name(a)<-i
b<-output$raw$comm
c<-a(b)
output[[method[i]]]$comm<-c
output[[method[i]]]$PERMANOVA<-make.PERMANOVA(c)
output[[method[i]]]$PERMANOVA$Rratio<-output[[method[i]]]$PERMANOVA$aov.tab$R2/output$model$PERMANOVA$aov.tab$R2
output[[method[i]]]$LII<-LII(output$model$comm, output[[method[i]]]$comm)
#output[[method[i]]]$Dtab.plot<-plot(output$model$SpeciesMeta$prevalence,output[[method[i]]]$Dtab, col=output$model$SpeciesMeta$M.Eval, main="Ratio of Rsquared for each taxon; using only environmental variables", xlab="Taxon Prevalence", ylab="Rsquared ratio")
#output[[method[i]]]$Dtab.model.plot<-plot(output$model$SpeciesMeta$prevalence,output[[method[i]]]$Dtab.model, col=output$model$SpeciesMeta$M.Eval, main="Ratio of Rsquared for each taxon; using only categorical variables", xlab="Taxon Prevalence", ylab="Rsquared ratio")
print(paste(method[i], " complete"))
}
# prepare raw metadata for lm analysis and model for lm analysis
output$raw$PERMANOVA<-make.PERMANOVA(output$raw$comm)
print("raw permanova complete")
output$raw$LII<-LII(output$model$comm, output$raw$comm)
print("raw LII complete")
output$raw$lmtab<-lm.model(output$raw$comm)
output$raw$lmtab.model<-lm.model2(output$raw$comm)
print("lmtab raw complete")
output$model$lmtab<-lm.model(output$model$comm)
output$model$lmtab.model<-lm.model2(output$model$comm)# linear model of env. parameters as explanatory variables for abundance of each taxon
print("lmtab model complete")
output$raw$lmRatiotab<-output$raw$lmtab/output$model$lmtab #ratio of lm of env from normalized data to reference
output$raw$lmRatiotab.model<-output$raw$lmtab.model/output$model$lmtab.model #ratio of lm of env from normalized data to reference using only categorical model variables (no explicit env. model)
print("dtab complete")
# do 1- : calculates the information lost per taxon
for (i in 1:length(method)){
# make the species-wise LII value:
output$model$SpeciesMeta[[method[i]]]<-1-output[[method[i]]]$LII$R
# make the lm output for each normalization: (this is r-squared, could be r value ...)
output[[method[i]]]$lmtab<-lm.model(output[[method[i]]]$comm)# linear model of env. parameters as explanatory variables for abundance of each taxon
output[[method[i]]]$lmtab.model<-lm.model2(output[[method[i]]]$comm)
# conditional statement to make sure that the taxon names match, then:
# difference in rsquared values (or r values?) from reference:
if(names(output$model$lmtab)==names(output[[method[i]]]$lmtab)){
output[[method[i]]]$lmRatiotab<-output[[method[i]]]$lmtab/output$model$lmtab
output[[method[i]]]$lmRatiotab.model<-output[[method[i]]]$lmtab.model/output$model$lmtab.model} #ratio of lm of env from normalized data to reference
else{print("Error in Dtab: names do not match")}
}
output
}
Summarize.PERMANOVA.Rratio<-function(trt, method){
Ftab<-matrix(NA, nrow = length(trt), ncol = length(method))
for(i in 1:length(trt)){
for(j in 1:length(method)){
print(method[j])
print(trt[[i]][[method[j]]]$PERMANOVA$Rratio)
#print(sum(trt[[i]][j]$PERMANOVA$aov.tab$F.Model))
}
}
rownames(Ftab)<-names(trt)
colnames(Ftab)<-method
Ftab
}
trt$rep1<-suppressWarnings(run.analysis2(commonN=30, groupN=20, singleN=5, D=500, V=250, method))
trt$rep2<-suppressWarnings(run.analysis2(commonN=30, groupN=20, singleN=5, D=500, V=250, method))
Summarize.PERMANOVA.Rratio(trt, method)
version(R)
Version(R)
R.Version()
make.scaled2
```{r}
?transform_sample_counts
?cor
?ecount
ConnStat<-function(ps, num=){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
out<-matrix(1:4,2)
rownames(out)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
out[1,1]<-mean(closeness(n))
out[1,2]<-mean(degree(n))
out[1,3]<-modularity(n, membership(cfg))
out[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.9]<-0
t[t>0.9]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
out[2,1]<-mean(closeness(n))
out[2,2]<-mean(degree(n))
out[2,3]<-modularity(n, membership(cfg))
out[2,4]<-0.9
out
}
ConnStat<-function(ps, num=){
ConnStat<-function(ps, num=100){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
out<-matrix(1:4,2)
rownames(out)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
out[1,1]<-mean(closeness(n))
out[1,2]<-mean(degree(n))
out[1,3]<-modularity(n, membership(cfg))
out[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.9]<-0
t[t>0.9]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
out[2,1]<-mean(closeness(n))
out[2,2]<-mean(degree(n))
out[2,3]<-modularity(n, membership(cfg))
out[2,4]<-0.9
out
}
ConnStat(trt$rep2$model$comm)
ConnStat<-function(ps, num=100){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
out<-matrix(1:4,2)
colnames(out)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
out[1,1]<-mean(closeness(n))
out[1,2]<-mean(degree(n))
out[1,3]<-modularity(n, membership(cfg))
out[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.9]<-0
t[t>0.9]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
out[2,1]<-mean(closeness(n))
out[2,2]<-mean(degree(n))
out[2,3]<-modularity(n, membership(cfg))
out[2,4]<-0.9
out
}
ConnStat(trt$rep2$model$comm)
ConnStat<-function(ps, num=100){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
out<-matrix(2,1:4)
colnames(out)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
out[1,1]<-mean(closeness(n))
out[1,2]<-mean(degree(n))
out[1,3]<-modularity(n, membership(cfg))
out[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.9]<-0
t[t>0.9]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
out[2,1]<-mean(closeness(n))
out[2,2]<-mean(degree(n))
out[2,3]<-modularity(n, membership(cfg))
out[2,4]<-0.9
out
}
ConnStat(trt$rep2$model$comm)
?matrix
ConnStat<-function(ps, num=100){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
out<-matrix(nrow=2,ncol=4)
colnames(out)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
out[1,1]<-mean(closeness(n))
out[1,2]<-mean(degree(n))
out[1,3]<-modularity(n, membership(cfg))
out[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.9]<-0
t[t>0.9]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
out[2,1]<-mean(closeness(n))
out[2,2]<-mean(degree(n))
out[2,3]<-modularity(n, membership(cfg))
out[2,4]<-0.9
out
}
ConnStat(trt$rep2$model$comm)
ConnStat(trt$rep2$model$comm, num=200)
ConnStat(trt$rep2$model$comm, num=50)
ConnStat(trt$rep2$model$comm, num=400)
ConnStat(trt$rep2$model$comm)
ConnStat(trt$rep2$QSeq$comm)
ConnStat(trt$rep2$deseqVST$comm)
ConnStat(trt$rep1$model$comm)
ConnStat(trt$rep1$QSeq$comm)
ConnStat(trt$rep1$deseqVST$comm)
ConnStat<-function(ps, num=100){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
plot(cfg, as.undirected(n), layout=layout_nicely(n), vertex.label=NA, main="Dynamic", vertex.size=10)
table<-matrix(nrow=2,ncol=4)
colnames(table)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
rownames(table)<-c("Dynamic", "Static")
table[1,1]<-mean(closeness(n))
table[1,2]<-mean(degree(n))
table[1,3]<-modularity(n, membership(cfg))
table[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.9]<-0
t[t>0.9]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
table[2,1]<-mean(closeness(n))
table[2,2]<-mean(degree(n))
table[2,3]<-modularity(n, membership(cfg))
table[2,4]<-0.9
plot(cfg, as.undirected(n), layout=layout_nicely(n), vertex.label=NA, main="Static", vertex.size=10)
table
}
ConnStat(trt$rep1$deseqVST$comm)
ConnStat(trt$rep1$QSeq$comm)
ConnStat(trt$rep1$model$comm)
ConnStat<-function(ps, num=200){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
plot(cfg, as.undirected(n), layout=layout_nicely(n), vertex.label=NA, main="Dynamic", vertex.size=10)
table<-matrix(nrow=2,ncol=4)
colnames(table)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
rownames(table)<-c("Dynamic", "Static")
table[1,1]<-mean(closeness(n))
table[1,2]<-mean(degree(n))
table[1,3]<-modularity(n, membership(cfg))
table[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.8]<-0
t[t>0.8]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
table[2,1]<-mean(closeness(n))
table[2,2]<-mean(degree(n))
table[2,3]<-modularity(n, membership(cfg))
table[2,4]<-0.8
plot(cfg, as.undirected(n), layout=layout_nicely(n), vertex.label=NA, main="Static", vertex.size=10)
table
}
ConnStat(trt$rep1$model$comm)
ConnStat<-function(ps, num=200){
require(phyloseq)
require(igraph)
o<-otu_table(ps)
c<-cor(o)
i=1
c[c<1]<-0
n<-graph_from_incidence_matrix(c)
while(ecount(n)<num){
t<-otu_table(ps)
t<-cor(t)
t[t<i]<-0
t[t>i]<-1
n<-graph_from_incidence_matrix(t)
i=i-0.001
}
cfg<-cluster_fast_greedy(as.undirected(n))
plot(cfg, as.undirected(n), layout=layout_nicely(n), vertex.label=NA, main="Dynamic", vertex.size=10)
table<-matrix(nrow=2,ncol=4)
colnames(table)<-c("Mean_Closeness", "Mean_Degree", "Modularity", "Threshold")
rownames(table)<-c("Dynamic", "Static")
table[1,1]<-mean(closeness(n))
table[1,2]<-mean(degree(n))
table[1,3]<-modularity(n, membership(cfg))
table[1,4]<-i
t<-otu_table(ps)
t<-cor(t)
t[t<0.7]<-0
t[t>0.7]<-1
n<-graph_from_incidence_matrix(t)
cfg<-cluster_fast_greedy(as.undirected(n))
table[2,1]<-mean(closeness(n))
table[2,2]<-mean(degree(n))
table[2,3]<-modularity(n, membership(cfg))
table[2,4]<-0.7
plot(cfg, as.undirected(n), layout=layout_nicely(n), vertex.label=NA, main="Static", vertex.size=10)
table
}
ConnStat(trt$rep1$model$comm)
ConnStat(trt$rep1$QSeq$comm)
ConnStat(trt$rep1$ref$comm, num=50)
ConnStat(trt$rep1$model$comm, num=50)
ConnStat(trt$rep1$model$comm, num=100)
ConnStat(trt$rep1$model$comm, num=150)
ConnStat(trt$rep1$model$comm, num=200)
ConnStat(trt$rep1$model$comm, num=250)
ConnStat(trt$rep1$model$comm, num=350)
ConnStat(trt$rep1$model$comm, num=450)
ConnStat(trt$rep1$limmaVST$comm, num=250)
ConnStat(trt$rep1$RA$comm, num=250)
getwd()
setwd("~/Documents/GitHub/Model.Microbiome")
getwd()
document()
library(Model.Microbiome)
library(reshape2)
library(ggplot2)
library(vegan)
library(dplyr)
library(plyr)
library(phyloseq)
library(viridis)
library(ranacapa)
library(edgeR)
library(limma)
library(GLDEX)
library(stats)
library(igraph)
method<-c("QSeq")
model<-suppressWarnings(run.analysis2(commonN=30, groupN=20, singleN=5, D=500, V=250, method))
run.analysis2
devtools::install_github("(“djeppschmidt/Model.Microbiome”")
library(devtools)
devtools::install_github("(“djeppschmidt/Model.Microbiome”")
devtools::install_github("djeppschmidt/Model.Microbiome")
library(Model.Microbiome)
library(reshape2)
library(ggplot2)
library(vegan)
library(dplyr)
library(plyr)
library(phyloseq)
library(viridis)
library(ranacapa)
library(edgeR)
library(limma)
library(GLDEX)
library(stats)
library(igraph)
run.analysis2
getwd()
document()
library(Model.Microbiome)
method<-c("QSeq")
model<-suppressWarnings(run.analysis2(commonN=30, groupN=20, singleN=5, D=500, V=250, method))
library(Model.Microbiome)
model<-suppressWarnings(run.analysis2(commonN=30, groupN=20, singleN=5, D=500, V=250, method))
devtools::install_github("djeppschmidt/Model.Microbiome")
devtools::install_github("djeppschmidt/Model.Microbiome")
library(Model.Microbiome)
run.analysis2
document()
run.analysis2
